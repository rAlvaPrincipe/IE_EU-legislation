{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticsearch Document Processing Pipeline\n",
    "\n",
    "This notebook provides a complete pipeline for processing legal documents and storing them in Elasticsearch with:\n",
    "- Text chunking and vector embeddings\n",
    "- Named Entity Recognition (NER) annotations\n",
    "- Full-text search capabilities\n",
    "- Duplicate detection and removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Elasticsearch Server Version: 8.13.3\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "ELASTICSEARCH_HOST = \"http://localhost:9201\"\n",
    "INDEX_NAME = \"anonymized\"\n",
    "JSON_FOLDER = \"./out_anon\"\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 100\n",
    "VECTOR_DIMS = 768\n",
    "MODEL_NAME = \"Alibaba-NLP/gte-multilingual-base\"\n",
    "\n",
    "# Imports\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import torch\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import logging\n",
    "\n",
    "# Initialize Elasticsearch client\n",
    "es = Elasticsearch(ELASTICSEARCH_HOST, verify_certs=False, request_timeout=60)\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    response = es.info()\n",
    "    es_version = response[\"version\"][\"number\"]\n",
    "    print(f\"Connected to Elasticsearch Server Version: {es_version}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_hash(input_string):\n",
    "    \"\"\"Generate SHA256 hash for a given string.\"\"\"\n",
    "    hash_object = hashlib.sha256()\n",
    "    hash_object.update(input_string.encode(\"utf-8\"))\n",
    "    return hash_object.hexdigest()\n",
    "\n",
    "\n",
    "def process_annotation(annotation, text, document_id):\n",
    "    \"\"\"Process a single annotation into the required format.\"\"\"\n",
    "    name = text[annotation[\"start\"]:annotation[\"end\"]]\n",
    "    \n",
    "    ann_object = {\n",
    "        \"mention\": name,\n",
    "        \"start\": annotation[\"start\"],\n",
    "        \"end\": annotation[\"end\"],\n",
    "        \"id\": annotation[\"id\"],\n",
    "        \"type\": annotation[\"type\"],\n",
    "    }\n",
    "    \n",
    "    # Handle linking information\n",
    "    if (\"linking\" in annotation.get(\"features\", {}) and \n",
    "        not annotation[\"features\"][\"linking\"].get(\"is_nil\", True)):\n",
    "        \n",
    "        linking = annotation[\"features\"][\"linking\"]\n",
    "        ann_object.update({\n",
    "            \"display_name\": annotation[\"features\"].get(\"title\", name),\n",
    "            \"is_linked\": True,\n",
    "            \"id_ER\": linking.get(\"top_candidate\", {}).get(\"url\", \"\")\n",
    "        })\n",
    "    else:\n",
    "        ann_object.update({\n",
    "            \"display_name\": name,\n",
    "            \"is_linked\": False,\n",
    "            \"id_ER\": f\"{document_id}_{name}\"\n",
    "        })\n",
    "    \n",
    "    return ann_object\n",
    "\n",
    "\n",
    "def clean_document_data(file_object):\n",
    "    \"\"\"Clean and prepare document data for indexing.\"\"\"\n",
    "    # Remove unnecessary fields\n",
    "    for key in [\"annotation_sets\", \"annoation_sets\", \"features\", \"_id\"]:\n",
    "        if key in file_object:\n",
    "            del file_object[key]\n",
    "    \n",
    "    # Ensure required fields exist\n",
    "    if \"metadata\" not in file_object:\n",
    "        file_object[\"metadata\"] = []\n",
    "    \n",
    "    return file_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document:\n",
      "{\n",
      "  \"text\": \"Headmatter\\nvault:v1:zP2W0S1FWCcjIkGfdEqkr+nR11fCKmklTwYMemteJQGhW45BNTC8uJuvRsCTxQ== Plaintiff, v. vault:v1:dUhZ91uEw0IJont2nC4BQinaiCTm+MOxrixS0EsFgb+1C6Z8pk0= Attorney General of vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90= and vault:v1:xcu0ZoKgo4jpKZK9ozzNV91tJ29h/kyaZjvbp9cKPpHDJksdOV0xhqVMCA== vault:v1:UPgn2Pv7o8lPoK/3PIWJqHnSATnKEWkS4K9Z9bO/X7PLSNsQEx4Truw=Attorney for vault:v1:2mpLLeYxfJGnfV97vNw0Dltg2lJvSHNxGaylXLhce69aopWhXAbuGfoq/kIJhB6h+sXXRHOxMXZriXLiC6//CFIiY5adUKpOPqiTj+19IXGNbsUN2tJsPuT4oesbof vault:v1:+U2CiFnqfnoTPeVFIgGFvJFH0w3fYOOkOYUd34tBncW2G7py Defendants.\\n\\nCivil Action No. vault:v1:HLcgeYOWoBGzEpxq/x8G29IO+WjzeiQY4UvGUm2OfSaSrrne\\n\\nvault:v1:UPgn2Pv7o8lPoK/3PIWJqHnSATnKEWkS4K9Z9bO/X7PLSNsQEx4Truw=vault:v1:a/vYEQYskkrsXlRXrTPI+02nE6AP+nuKdAJgoEQqDuraKNIKkkqvPxEb vault:v1:BYkIRWZfuyRqB3a7Cc51jlIDJSSlypzaDSbYHbyrZ0BbunPhcNtsG/tuFQaEjlE1nB2LmIfGGJAElEofZ3LekMuLXg86I0AUf7L2QyEN697yjvvP+Q==\\n\\nvault:v1:a2xO6NohGmbOKNhSuZVZi+m6JcVimi/Qt+83j/OVrEavVYdSCNkrLDU=\\n\\n*749 vault:v1:gvELF3YrUa2gggEvSuzZ5wUh49MAZdyUH7o0Io+ltdFAFOV09vmLFEE= vault:v1:uk7nAxYvx+k4sqAu8mXt7mN6RgTjW1jmuGwraNkVg/XQynL360VmRhRsQA== vault:v1:xKLf9Mhq4PdtSVUeeErQmemVjb5fYS9awqYDwhCizspCDWhnyIzW2YZY/GSR vault:v1:9VaiHgRzP+I8rDiOL8hBi4C8onblVxg/VN2CFkkSgHGPSA== vault:v1:wS5AoP8VwGZSbT04p8E/psxqUezO6OKG7LCe5J3y for plaintiff.\\n\\nvault:v1:ltGq7u1uPfMFJArtbW6fHnnC61h4JIs7wBm6mnLyTycxgRIrZGlGBMCGRFkhcA== vault:v1:4xN+jSvD4EZWMIxaB4D97gcHUrUnYStN6Lna3Qn7whA=Attorney\\u2019s Office, vault:v1:msPp3tM9sv9KVFsD/TA91VtOARy2B3KUM5gfzjjOy5VeJQYc5oAxL1M= vault:v1:+U2CiFnqfnoTPeVFIgGFvJFH0w3fYOOkOYUd34tBncW2G7py vault:v1:OlKz4HJXHcIANSnySgddw3YFG8OImercC7ZftrR8Tnxw vault:v1:rDQvhzBieqjZQCqSshaIN6l8hXFn8dLY1gz+zO9eE7Lf7TESSDWUtQ== vault:v1:uGgiAngIOh6lIHqNSRRD3BpehHxPzr2yXX5ZD4vJ2GtB+lduZYiMHmmL1nhVDg+qvZhYkIDsQYkCuyLc73eN vault:v1:hDEt56NIrQdyc89LV+OWDNV01qVVcyBflfylS/B/1klC40lDcyYmSYWpAy5FNP2QrpxMvTAFeC5HKj7t8O8Sqyuew8bJnidkGa8vsdC+ vault:v1:KihNeCnQkCnXl6PGjLvQ63VzthOzJXjJ4NizrqB60WmWxwCFsuB3oQwhTgU= vault:v1:KihNeCnQkCnXl6PGjLvQ63VzthOzJXjJ4NizrqB60WmWxwCFsuB3oQwhTgU= for defendants.\\nCombined Opinion by vault:v1:xXgrvbAhhlV3Wb+ZeytEPML3+0uX2Pl3E8wlFc6MKuBTQeD+coOQYlFcb8FtY1Y=\\nMEMORANDUM OPINION AND ORDER OF DISMISSAL FOR LACK OF JURISDICTION\\nvault:v1:xXgrvbAhhlV3Wb+ZeytEPML3+0uX2Pl3E8wlFc6MKuBTQeD+coOQYlFcb8FtY1Y= Chief Judge.\\n\\nThis civil action was initiated by a complaint filed in vault:v1:aKmcEFtifCjd7LwZN2AHrt4v+akZX8FbaAlW4+vVyNLKaw/35AVsm6rAd8NxbVhIW23lh3Jwxeg=for vault:v1:2mpLLeYxfJGnfV97vNw0Dltg2lJvSHNxGaylXLhce69aopWhXAbuGfoq/kIJhB6h+sXXRHOxMXZriXLiC6//CFIiY5adUKpOPqiTj+19IXGNbsUN2tJsPuT4oesbof vault:v1:+U2CiFnqfnoTPeVFIgGFvJFH0w3fYOOkOYUd34tBncW2G7pyon vault:v1:CDyoKdoo//W2fDcR+HxTB1uQ4u6p6AC305zlxwnRwp3vM2dM69aCA+fQfa4pNA== by vault:v1:srybCnBuG85chwMmYXOaDqdpdaquPwxd2Kg/oYEptgMqpAV5nYer81E= who was then incarcerated at vault:v1:iB4FAAgWGJFtnVevxnJDExBAeTikZny3DZcMDS8oUJk7MKGoFpvFe1Ymh78FLT253qe/1A76/wkgoyBsM3d8hn9Rspei vault:v1:rOAk6UprvjAm4kJ9Hy8hRZtdf6e73sR+0YmVB0ep5n25s0oSNhLwknA8OMe1 vault:v1:+U2CiFnqfnoTPeVFIgGFvJFH0w3fYOOkOYUd34tBncW2G7py Mr. vault:v1:CARbxThrzhZMrRWIspEamjklio8Lv8SH6XXN3nomzHtIp155nWPVFAyqR4mWj5XF0siskA==is a defendant in a criminal proceeding now pending in this court as vault:v1:fXHpYsI5i3oqZRNDdWFrn8+bOBPyzPSjj0O1l5W3XeT5LLRjzHxfPhsW6NDWmVDE768wJHEqY5WoBecause the criminal case was transferred to this court on a motion for change of venue, this civil action was also transferred pursuant to vault:v1:Y9t8NufL7i+CAxWNI6bimTvCuR1q6t7O2HDHTqMP0gyThn3iv6TUYFEH8oIyFKU= by an order entered on vault:v1:WbFjD/WLheynPwa3YXqAUS6HdNLrqNM/qUwR8yX/NtLCZF5g5JQ2byH8nQ==\\n\\nThe relief sought by Mr. vault:v1:CARbxThrzhZMrRWIspEamjklio8Lv8SH6XXN3nomzHtIp155nWPVFAyqR4mWj5XF0siskA==in his complaint is an order declaring that vault:v1:ejVre4ZIE4hekK/TcoduMcMPM2ohpargyENU120wSjZF+idAppRlTBUiAyp0xR3Xq/5atuA9P5Pspspc59NmdotKN3h9Bt9fKwC8gosnSkjru6+LRG4fflDyKxHUvault:v1:srybCnBuG85chwMmYXOaDqdpdaquPwxd2Kg/oYEptgMqpAV5nYer81E=(\\u201cNotice\\u201d) filed by defendant vault:v1:xcu0ZoKgo4jpKZK9ozzNV91tJ29h/kyaZjvbp9cKPpHDJksdOV0xhqVMCA==as vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=Attorney for vault:v1:2mpLLeYxfJGnfV97vNw0Dltg2lJvSHNxGaylXLhce69aopWhXAbuGfoq/kIJhB6h+sXXRHOxMXZriXLiC6//CFIiY5adUKpOPqiTj+19IXGNbsUN2tJsPuT4oesbof vault:v1:+U2CiFnqfnoTPeVFIgGFvJFH0w3fYOOkOYUd34tBncW2G7pyin the criminal case on vault:v1:ea7pt1r3SLTVhbAmjGFhATbflJLxZacrhSHUTh5qul81Yy6PVFKDejOun5qo is void and of no effect. The plaintiff also asks for an order prohibiting the defendants from filing a new notice *750 without compliance with his interpretation of applicable regulations, statutes and constitutional provisions.\\n\\nMr. vault:v1:D+I+5abaJ1EJT+z7gvEkItdB9EmTXRS65PkyyKKmUuzSBlk=alleges jurisdiction for this civil action under vault:v1:taFKOQGYJHHoeDk26rh58jVbJb3ZlHfpyNVmBIZ++fw3OVtxGK9NSLU5Sp1Tds+4aOLDUMNnlCa4nBEg8Lw= vault:v1:tA0t4uTPwlu/BzuYATNAM46JNPDkxn0dy4g1rHxwPBI=and vault:v1:h/S+Wrfyg8Vshh4v3vUDYmayjunLiJEfpBaR94Y9ZkE= The federal questions raised are claims that the defendants, in their official capacities as Attorney General and vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=Attorney, violated vault:v1:XWxABWGfchR55mgg2JhJF98uR4LwGl2YExIluLXA6fotKutagX3qLdy9IOf75CIl+mdPCY8ceNTw7IpYSaSPlrEXlcDnkI1S vault:v1:kCJ870ggsIBU5iLgsCrFkCGAS6QsJs39906ZVjFkHEXdl7WHdZli+wc=vault:v1:BCEcqlYlntsUpngTfludPaVYmL23V8uXIRjA2zL+CpSuaof4S8D1 vault:v1:dgn+ZL0GgS8g3HTwGEaJ1EOPSsFJuDaIJ8HoibA/Osn74RUEkdrbFQjtXW9N3y39o3U16h0= vault:v1:7OTUMNwWV29s2FcGU9X8S7csokdKZjfSmULqkjUDDK5G8i3KqabJT+saNAo=and vault:v1:Y04hdeoGifgT0PbeIKBEWTqkxPPsCV5aAnpkWv9jhhJbjcHTwhb+CxNLEt9hZQ==of vault:v1:9JhRETb7kcFINR5zJMGo1WQ6PZOTjRZ/j33UyXok0iF5TuXFsxC1r3rAmReucI3N+WXItpaoeEnslmwGV1mbE8RtXdI+rrpLkTFiJ8I=by the manner of filing of that Notice. In particular, the plaintiff asserts that defendant vault:v1:Jd+mJPeWRVjIjyUo3Cp77e3zphErNKndqlXWubDVl1c=was not an \\u201cimpartial decider\\u201d because she had publicly announced an intention to seek the death penalty before any charges were filed against vault:v1:srybCnBuG85chwMmYXOaDqdpdaquPwxd2Kg/oYEptgMqpAV5nYer81E= that both defendants denied the plaintiff access to any record information forming the basis for the decision to file the Notice; that the defendants conducted proceedings in secret; that the decision is without basis in fact and law and that they failed to give adequate notice of the issues and evidence on which they would rely.\\n\\nThe defendants filed a motion to dismiss on vault:v1:wnPPDjdvxAvOc9su2bwYDuBLQbnJD+zon/4epG8mIGTlCpUk+iE7oMP5Ar2w pursuant to vault:v1:odpTAAZIlBGA7XYfhNV45EtLbGzkHLhFki7qaR3WoDVZMGVp9UL91B2Oand 12(b)(6) of vault:v1:zoR8cTOKdunxIMsFaDta4DgEecNCop63bvu5qbJ7BH8S466HbxMSRIB51m/vTpMEcJ0O8s+8fXOH2ZPzfor lack of jurisdiction over the subject matter and failure to state a claim upon which relief can be granted.\\n\\nThe Notice was filed pursuant to vault:v1:+a7xMGWHJ5PAxehufdJUSHO2HHiVNnaCaCq5UUBs/xDMiNaJlTqmEQpodNtDah/c That statute reads, in part, as follows:\\n\\n    If, in a case involving an offense described in vault:v1:AlQpAkFfP0KIFlstAwFu+iLC4R1hkC1A+gSGkki89CtYY9od19YKn6ZVw2PpWYZAmA== the attorney for the government believes that the circumstances of the offense are such that a sentence of death is justified ... the attorney shall, a reasonable time before the trial ... sign and file with the court, and serve on the defendant, a notice\\u2014 \\n\\n    (1) stating that the government believes that the circumstances of the offense are such that, if the defendant is convicted, a sentence of death is justified ... and that the government will seek the sentence of death; and \\n\\n    (2) setting forth the aggravating factor or factors that the government, if the defendant is convicted, proposes to prove as justifying a sentence of death. \\n\\n    The court may permit the attorney for the government to amend the notice upon a showing of good cause. \\n\\nThe statute provides that if a defendant is found guilty of an offense for which death is a possible penalty and such a notice has been filed, a penalty hearing must be conducted at which the defendant may present any \\u201cinformation\\u201d relevant to a mitigating factor and the government \\u201cmay present any information relevant to an aggravating factor for which notice has been provided under subsection (a).\\u201d vault:v1:J7/khV9kBGkqHC4YjPcvpUk/rgoTdNkmb6Q/O2jgSOoTKxAANnBwFp15ZEfq4q0=.\\n\\nThe \\u201cattorney for the government\\u201d referred to in the statute is the vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=Attorney, appointed for each judicial district by the President pursuant to vault:v1:DXodngkhl1t30k0fpFPr8FcYAgbbodhtEKO+5oogpdBLpKmdbBNPYWZWjNQ=with the statutory duty to \\u201cprosecute for all offenses against vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90= within his district. vault:v1:4FOMlzA3eMNMsBfj3N3xBQyMMZl/1NnLj9urSx+kPGWXiPD/3YVK5x5q7Do= The Attorney General of vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90= appointed by the President under vault:v1:5BjmkP248V/QLIZoV9oOp70DjvO1ZlRRLTpQjaVgknv7Wh7sRV8tiHt+a7M= is the head of vault:v1:uGgiAngIOh6lIHqNSRRD3BpehHxPzr2yXX5ZD4vJ2GtB+lduZYiMHmmL1nhVDg+qvZhYkIDsQYkCuyLc73eN an executive department of vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=at the seat of vault:v1:vjhHeT7FfPnhVkyEr4WQ1GT961YjxEnSosye8Jk1nDQBB+97hr8= vault:v1:MRKXcNj37/a6zKEDcMg5TxCxSxIw04I5fcxM+5TjJr1/YYlKylcsQD4OEmM= The Attorney General has specific statutory authority to supervise all litigation in which vault:v1:QrlwyZotU4vQms1QwJhFpF6xF1zQHoBrkGsswMXTio5aC3IGhF0z9JNAIyIpis a party and to direct all vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=Attorneys, and their assistants, including special attorneys appointed under vault:v1:MnTfdtok1+ns5AuVFAQkMIkFQi9/csW2UskDlEYt2ivlgfmcS1Avto assist vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=Attorneys, in the discharge of their duties. vault:v1:c18iutg5G4GiakEK3jzey63eSNLaJV08H/RJMZU3FOLfERaGRr7YgNlm3cpE\\nAttorney General vault:v1:dUhZ91uEw0IJont2nC4BQinaiCTm+MOxrixS0EsFgb+1C6Z8pk0= like her predecessors, exercises that supervisory responsibility, in part, through internal policy directives collected in vault:v1:WeIuugjI7qES1yGBXW7HEl8FWBFd1GmeeS7Tl21iUjQxy+tCqARpklAgf3oRSCigMMv+7r6QHpDPG3ZFOmNj0ZGAUA==vault:v1:TkyBVAEYDHwjEsnB9A/vjBDwnrjAiIVzAfpffTqjs2CqOzl7PIdZcz4Wl+RsNO6b8+fl27MMCjZfN5U=). On vault:v1:5appCLqRQTtxM/MAP6mfM9Pod0cKHAoyh0ub0wOaQ0HmAkDr8ETXf4SZcxtE following enactment of vault:v1:TokuhOc09dnPBbEWKt1bqUvBoHIYnNTxSm7p8M3xNqLkJ4W+nYR+oyncwODFOAdbRWKAJl21ymu3ocp7QTfurUeYNXacfV/UZe8LVxHvwmor the vault:v1:7Wk8b+b/i73MFzJLegwvIJr7KZ7bDg73HqvGuLxvzMhPRZQcVt3pD41QJd31Ib41p7UPmUXVpGg+pH4=was amended to require the vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=Attorneys to obtain prior written authorization from the Attorney General before seeking the death penalty in any ease. To request such approval, a vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=Attorney must follow a departmental procedure which has come to be called vault:v1:edhadgXaPKBTkJ/JYD7P1E2oXUpJvB9gOEl5uHTSaIcW9A8cRx5DP4WVmyKyPuYDewmGtOMJRM4y\\u201d The vault:v1:z2+5Di6N/2aDi/7qBa7A7hRtrojUc7lAVVZwD1qKP8qFcvHurequires a recommendation by a special committee of vault:v1:uGgiAngIOh6lIHqNSRRD3BpehHxPzr2yXX5ZD4vJ2GtB+lduZYiMHmmL1nhVDg+qvZhYkIDsQYkCuyLc73eNoffi *751 cials appointed by the Attorney General. Before submitting his recommendation to that committee, the vault:v1:UPgn2Pv7o8lPoK/3PIWJqHnSATnKEWkS4K9Z9bO/X7PLSNsQEx4Truw=Attorney must give counsel for the defendant a reasonable opportunity to present mitigating factors for the vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=Attorney\\u2019s consideration and defendant\\u2019s counsel must be afforded an opportunity to submit to the committee, orally or in writing, a statement of reasons why the death penalty should not be sought. The published vault:v1:z2+5Di6N/2aDi/7qBa7A7hRtrojUc7lAVVZwD1qKP8qFcvHuincludes a policy statement that the vault:v1:UPgn2Pv7o8lPoK/3PIWJqHnSATnKEWkS4K9Z9bO/X7PLSNsQEx4Truw=Attorney, the committee and the Attorney General may consider \\u201cany legitimate law enforcement or prosecutorial reason which weighs either for or against seeking the death penalty.\\u201d vault:v1:VgRPiBgZa9fPUVG8GasUJHrI3eq90ugP6a4TJOot/pJiDgpCOzhjme+bp95bP8zF+TY=\\nIn the papers filed supporting and opposing the defendants\\u2019 motion and at oral argument, counsel agreed on the following facts: On vault:v1:+i2z5jQfLE2UfjAlFc/QwAucxqrDirQxbfrauTp0TMNIEFJjZbN5ohQ1 defendant vault:v1:ODFyscgoEz8/RP9o5XTMePJqNTjYu16pH0UvkDqEJAo=wrote a letter to vault:v1:gvELF3YrUa2gggEvSuzZ5wUh49MAZdyUH7o0Io+ltdFAFOV09vmLFEE= counsel for Mr. vault:v1:D+I+5abaJ1EJT+z7gvEkItdB9EmTXRS65PkyyKKmUuzSBlk= inviting an oral or written presentation of any facts for consideration in making the penalty recommendation. In his response letter dated vault:v1:CmdGXFYq+qesmWQBq6o/cqjbMSuzUmFR8rPHImsa6VEwWZGu4ptuM8N8 Mr. vault:v1:gvELF3YrUa2gggEvSuzZ5wUh49MAZdyUH7o0Io+ltdFAFOV09vmLFEE=requested that Mr. vault:v1:ODFyscgoEz8/RP9o5XTMePJqNTjYu16pH0UvkDqEJAo=recuse himself from the decision making process and asserted a failure to follow requirements of vault:v1:XWxABWGfchR55mgg2JhJF98uR4LwGl2YExIluLXA6fotKutagX3qLdy9IOf75CIl+mdPCY8ceNTw7IpYSaSPlrEXlcDnkI1Sand procedural due process. Counsel also objected to any participation by General vault:v1:dUhZ91uEw0IJont2nC4BQinaiCTm+MOxrixS0EsFgb+1C6Z8pk0=because sh\\u00e9 had made a prior public announcement that the government would seek the death penalty against those responsible for the bombing of vault:v1:JtH2ioHiCSZTCWuK4PkI6zG6PvQeu18R2NL547wpiwp1UOHdJrV16gCncAxyPrdEPZuFhq0DMIPnjOxg+g== Mr. vault:v1:gvELF3YrUa2gggEvSuzZ5wUh49MAZdyUH7o0Io+ltdFAFOV09vmLFEE=also made oral presentations to Mr. vault:v1:ODFyscgoEz8/RP9o5XTMePJqNTjYu16pH0UvkDqEJAo=on vault:v1:DInc44Jfiory1KJm2gGVuWIOS4sXRUudIjtKPh8drGsgaLHJQrL+BFw= and to the vault:v1:uGgiAngIOh6lIHqNSRRD3BpehHxPzr2yXX5ZD4vJ2GtB+lduZYiMHmmL1nhVDg+qvZhYkIDsQYkCuyLc73eNcommittee on vault:v1:rSucTEZgkU3hzR8ESaTgDZhd2VZZZNb6fLFCVcIQlGAx9MUil+/GP8KlCFUPjg== The indictment was returned on vault:v1:5YFN2i9KDMSv39EsrW6MVnBfwVLzqcB+Z7vIGkBQ+CDKLehi2sGhG659M/U= and the Notice was filed on vault:v1:AgJuw2guVpgOBiieFQkUAIWbpDOAizhtsl9qCcuwUdaEDFOWI01SX1WB8rc=\\n\\nOn vault:v1:hhG0OdmFEd66O8kgrPlvX0MHgUc/Ouv4q4Bfy0bcsCw9yh4EzEnZNxt1 the defendants moved for a protective order denying the plaintiffs request for production of documents, served on vault:v1:1FxpAmmVoTtY6/bKOgryBDCVTqUtDGT2WM3OuctSbuBmD1YlZUdR7uInBEcs and asked for a stay of all discovery until resolution of the motion to dismiss. That motion was heard with the motion to dismiss on vault:v1:P6ze/OfAtmvLR+B3Yr9B6cZKyceFH5OOnOm9NprZr7BXGeNwB18+foTo The plaintiff contends that he is entitled to copies of any reports or recommendation made by Mr. vault:v1:ODFyscgoEz8/RP9o5XTMePJqNTjYu16pH0UvkDqEJAo= including all supporting material, and copies of any .reports or reeommenda-tions by the vault:v1:uGgiAngIOh6lIHqNSRRD3BpehHxPzr2yXX5ZD4vJ2GtB+lduZYiMHmmL1nhVDg+qvZhYkIDsQYkCuyLc73eNcommittee, or other personnel concerning the decision to authorize seeking the death penalty against vault:v1:srybCnBuG85chwMmYXOaDqdpdaquPwxd2Kg/oYEptgMqpAV5nYer81E=\\n\\nvault:v1:XWxABWGfchR55mgg2JhJF98uR4LwGl2YExIluLXA6fotKutagX3qLdy9IOf75CIl+mdPCY8ceNTw7IpYSaSPlrEXlcDnkI1Sexcludes judicial review of any action or decision \\u201ccommitted to agency discretion by law.\\u201d vault:v1:qgE16wqAhmlwzlDoY3b3DNaWsJYO/9d/SEMfcSRSljfpYQv4dIio2qIcyXT0kEL4bw== The prosecutorial discretion to make charging decisions has repeatedly and consistently been held to be presumptively unreviewable by the courts. See comment in vault:v1:JWBojrbABAghLt2h7DL5egAA/AfRcrtPuhLfMtKuk23Uj80=v. vault:v1:sOb7XX7hm/QxPj4vacMxT1S0DGh7gpBrcXPXMTD4AzcvIC+0SIIG7+a44+Pp vault:v1:eWgPKEQlYZVHHwz7usOYCFoGHAeTmWCdoaTrgYM4vA==U.S. vault:v1:sDz4IyL4XUAktYTkdJTOZF2pZkmnx71245fkrqzehw== vault:v1:azVZEuuvUoWPUQJV4hlQxdx/VI8iIMskXAg0e+cR+A== vault:v1:DAN5aFm126Pit6k7sJHNBr8OaM/cPTpeMJT/YopuvA==S.Ct. vault:v1:hWiB3uvmJ4s5d4nFgPITw+2OedvvkkldrFD8EnleKGos+llyb4GpBHL9US0HEplzhYstv4LISmT5DaBm3HrAGc+NaHpX1V7YUGaO45k8Kw== vault:v1:gPOH5ZsllDuk1b0WR24OpHe5Zqab6U1hhGh3RosaLIg= vault:v1:m6+onZCOkgiyVgUHp/OMgoJlOO9o1i4K/N8jT/BZL.Ed.2d 714 (vault:v1:VXsTk98oJ7mF8IAS+MVTr6VYNlKlqRN/hGYpoOPtQosx and holdings in vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=v. vault:v1:WM44gH6vvyP0qgBoRdtMsDJJ/34EfJcPq3ewReNpIf0jdmuwPLSTolPtCZ+YCVa+hni1q92f vault:v1:Y6Q5b4JY+/s2iud63skeZfZszB/d/YE9c2coOWVYF.3d 1423, vault:v1:fbPQSnFyqzfAczgoFHADGT0Thp+kQ3Y3SoCYaGUEDe9t0kI=(vault:v1:3+ySKi+FiDSbJ0ugJTKVhJKq07a0EyID34rOq9b9M5g=vault:v1:zY+MoxdGVh0Vd6+ti6IL+lIOF6jYJ/rHktmKhu3CGg==), cert. denied, \\u2014 vault:v1:4xN+jSvD4EZWMIxaB4D97gcHUrUnYStN6Lna3Qn7whA=-, vault:v1:ef6HI4wc1s5RFR1Y/l0bUE2bTzaq5tLTIA01SeZJxQ==S.Ct. vault:v1:keUXFC3Fkqnci0yUDMzQlRuAdabBX7LVk4UzVFK/uw== vault:v1:keUXFC3Fkqnci0yUDMzQlRuAdabBX7LVk4UzVFK/uw==L.Ed.2d vault:v1:ZOB4393KuM6EDa/fsv0Im65ykSlU5Pd3bCh6RGqQ(vault:v1:FJIpiefu99pHxPxZPhY7FVe48P5EIoVmvuEpq5HX1nFe; vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=v. vault:v1:SS5OrpRTh59GXdcxr0oJA/XF8C4x+++QpZ7QlkYGmV2qIA== vault:v1:t1ZhdMdVTS2CU8tQtd6LNRbchRDgivpjWgBKP1thF.3d vault:v1:3JgTcpmuwxxM7KbMM5obeWOpMVWcIrrJVUGKWpsmSg== vault:v1:DtYmbd/JBdHlndIXuWvJGxzBnoHpjCduPkWmEpYwtg==(vault:v1:3+ySKi+FiDSbJ0ugJTKVhJKq07a0EyID34rOq9b9M5g=Cir.1994).\\n\\nThe plaintiff does not dispute that presumption but contends that the Attorney General has restricted such discretion by the adoption of the vault:v1:z2+5Di6N/2aDi/7qBa7A7hRtrojUc7lAVVZwD1qKP8qFcvHu Agency decisions have been reversed for the failure to follow procedures of the agency. vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=ex rel. vault:v1:7zD0jPn7RoRfF62n5zq+4ddEDVRVo2tCQviTsdwzeQ5nFij26yMOQquADA2hohbO9ZlJpvG+YSs+LKNc/UnooCscz7jK4lSyv. vault:v1:NSpFuO24BrXAVN1bMrvofJt1CJBbEOYxxXGTzAygtlXpx697sKZc vault:v1:eDfCU+RlerAJAjYDpa1LQpKRpVyDTSd7zYLUo+8S/g==U.S. vault:v1:EVcw8YFhRcqkCHisQsHzHo7SyYefjpojNIrNFVBPtw== vault:v1:wohMUke2Gvn09rxPWo6f3dcy9FB4rMJWji/Bk41GS.Ct. vault:v1:XdP/Ez0KqCF2rJY1GjrLQkWnCFaUp212QbUbfDaCcQ== vault:v1:krUDAVOOoajXfeerbBWK69b0DFaZ0pYxJZRdfHPtL.Ed. 681 (vault:v1:tOZF/aX9NSiJu1O3PYtIHPeTgcGYsst/0ANmbajx+X0a (deportation decision of vault:v1:eQFXD9s12GCTPdDxxiTXgo+sbLmOU1ttgtrN6vZTKxwUMdaLMVlIyECGqsq/rPxe4lc9xg1a1E0=; vault:v1:lAZYcxMvpMBI6JH+Yme0vnkCjHwlZ9vxcdY6mIE/EqXe2CQ=v. vault:v1:JxJas0wHcs/bc8b5wKXAY77Ea5iqd/e0S6t6O5Ts/oCwFEzEi/5UJMCl vault:v1:/Qy3NRGn0UAFOcel4HqXYcI6shmGTCoeqx9JguEJxw==U.S. vault:v1:KHSxk0l/eYQnfGegRPIf5Za2VMrjxb1EG5vh48T/NA== vault:v1:TqO28KCLQbWBQcrPJkiYo0UtrpFk4AHiHYNJuP6gS.Ct. vault:v1:w09mLl1ZLm2jZ/azAI2U+jdoPpqHHF6E0XHRZyJqWCQ= vault:v1:WiRZ73lxGI4RGu9RXlfei6bV4UInVZkA+KSv1Fg=L.Ed.2d 1403 (vault:v1:iiH7UuQQxz/vMSwdO1sOOqP3Cz3tADRjTYIEGDtl9w9I (dismissal of vault:v1:DzAvyUdtu4qWYIzmjumdRNbLOPXo4U00KW1+z1W/sRcODIU6mhK2VToYQyndmb8OjxEu6B8uXpek3b83TQ==employee); vault:v1:6HyB9jsq60rzTD+5zdpOyH6tNWYNn4WJdB4Uvu0GYJjO3PN+ag==v. vault:v1:ilFwjr3V7t+8G3Sh59Y8wWuii6tVHrZHtHdgRxCHbmHUEA== vault:v1:vAbKTpJnCjCdt+6mUGwlse+0dtfnqRLoLs39EH0Pnw==vault:v1:4xN+jSvD4EZWMIxaB4D97gcHUrUnYStN6Lna3Qn7whA=vault:v1:DysNUOasMw61U7zClCro1zvwB3BIJ5feUYOpYvcZmQ== vault:v1:5OxvoT7Kk41e/MRrMZvxeDjzo1o/PRbVormL2P8fS.Ct. vault:v1:l6S+LyGV8JwUR0D2sF84gYKK5kXUM/ERz0cc6xktoA== vault:v1:slIDnFOhLS7twD8/x0U0dawGqvLmGA0y2WUgSz0=L.Ed.2d 1012 (vault:v1:mRM7/LLg0ui3GHgmcZR5KRK8/OnRBoRe/lEibsr6EYk1 (dismissal of employee by Secretary of vault:v1:emxrOWna6E0kfwAxnL16N76OjEgSMNjO0JLr8w5+WAvXl2txGhmvhgfOdmC69zMaKnBqz/hpQL4qB1U6SyMbhzespOY=; vault:v1:iY/bn3/yavSn2DKRCvqjbRTx8okwJ9w4DlO7iodJOLWuNQ==v. vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90= vault:v1:IFUYU4vEFRTCSYvrZpFOsVm60J4TvGk/RlBqo+Q5ow==vault:v1:4xN+jSvD4EZWMIxaB4D97gcHUrUnYStN6Lna3Qn7whA=vault:v1:Qr817j/U0Li3DiyvDTqXdJKu3xORtKEyfKWhPbyung== vault:v1:WhjdVlt8NG8Uzrhz4t8DrvCGFvG+eIPMTuyH0RcDS.Ct. vault:v1:MezsEO1m7ZzM97pdiaZaXFnXb4BF2jC7QypBj7wr+ael vault:v1:2zVH7vj4PKjG9J7adqk6JJuz9sxzFo1a50u8BAmTL.Ed.2d 778 (vault:v1:OB1ZYi6LpsI20qq/RXoYuXHhpgjQOr1ZgFFhWYlrmwn0 (criminal contempt initiated by vault:v1:S11PseeNuZ/aCdyzDAYndVvTimC+km9trPHveKiU1ND5XFHm2s+ABXk2KDhMAz5+Hx0=committee) and vault:v1:Ho6+5BVmEFJgQmhDOHO23kX7YL8z7ExE/ibvf21YuQf7Jw==v. vault:v1:AmgxpUQ8QT6QKEcQXpDTNf0Y1CQy6d7B5KU1IoMAXj0= vault:v1:9t9ik9j//O6Z7FAgBAX4dGHZQRq3GD4ukJuWHBrNtw==U.S. vault:v1:gSQsKgxRMvCFkFjLfykfJpbZE34txzTkV6oToOFSrg== vault:v1:zOy2YQ5CTZINUl6sfBCgnjxVRygOVN+HSmyYBuu/S.Ct. vault:v1:7BxlDQn//UaY8Yh8m0In16lNzx+Jtxk2U1PyhkgXOz0= vault:v1:t1ZhdMdVTS2CU8tQtd6LNRbchRDgivpjWgBKP1thL.Ed.2d 270 (vault:v1:upgtsFKa2r5olwF1iZw8JZAHYDJM/R1fiCMQiWFXg2Fp (vault:v1:85BUNzwxcIAD9MO+/xQSkaHDQjFME7cIBlFYx/1doe8tRG7jUEipZQPEItGbsMHkTFwqng==denial of general assistance benefits). As discussed in the plaintiffs brief, these cases are premised on the fair play concept embodied in the principle that due process of law is required for governmental actions that affect the rights of individuals. The agency decisions were adjudications and the agency regulations both created the interest to be protected and defined the process due to protect it.\\n\\nThe applicability of this line of cases depends upon a finding that the vault:v1:z2+5Di6N/2aDi/7qBa7A7hRtrojUc7lAVVZwD1qKP8qFcvHuprovides vault:v1:srybCnBuG85chwMmYXOaDqdpdaquPwxd2Kg/oYEptgMqpAV5nYer81E=with some protectable interest. It does not. The vault:v1:UTB5ceoltssBYABqz0cS+8AxVuvehhE7u5Lj8iUeqa6+Bg==expressly disclaims any intention to create any judicial *752 ly enforceable substantive or procedural rights in any party in any civil or criminal matter. The courts have consistently refused to recognize any such rights with respect to many of the policies and practices prescribed in the vault:v1:UTB5ceoltssBYABqz0cS+8AxVuvehhE7u5Lj8iUeqa6+Bg== vault:v1:3Bi6XluMPyPk6E8I0WXfVr3Ah6+aOddK1IVn8AuHw9Ym7mLQbOllTZlN+HvdnD6WvWBlNMC7/buq0mfENHUYxtqXa1qc6KLn7G6LSte5B64=followed the other circuits in holding that a defendant in a criminal case could not enforce the \\u201cvault:v1:4xRYAHqjxWh/s1+btYm6og8+EJ6KYfRtg8KJ8yV/N1iBAQ==policy\\u2019 concerning successive prosecutions in vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=v. vault:v1:VQaUSENSjVgLpuZchXDMjT3EPoHuyHf39k/Bgmc1wfqOC8q0 vault:v1:bz2qxHG4SygxqXbYuLYjpR8P2F4Vc2euyTQy8Pbe+w==F.2d 1184, 1188-89 (vault:v1:nksshBGCoNP57dImNb+6UCNGOgpa9huvppV+3z2O+01Hy0WLjg== (en banc), cert., denied, vault:v1:yDFhMvjunQmhui8kI9zjCW8s90OrfczVqTMUy0VyBw==U.S. vault:v1:JPAEDc4ExxbO6+AC6Iz0E+AXfmfea1aklifYg5efs6f6QQxlUQQx8xEuOWBxOAZqvw== vault:v1:+T54NBcMrotsv4TEVWknWbXrzx00t6Ocj4UOsQsuS.Ct. vault:v1:a7AaMl11cVgpZtxCunyNO9UonXQFvygsTKeOBPzkMQ== vault:v1:mJ+9JFR5YOrnPxmK6P2xp3keNiHFbbN5U1YhBRY8L.Ed.2d 243 (vault:v1:acEZK8pKmui3XvpUb4BWjOSuLcqShNm8nozHtRHWCcQR and in vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=v. vault:v1:8XNTokuvlIo5TtISIvv4PBlt4zNOI+lMumN3OS6fZYu6 vault:v1:1DAfiNmFkzIAeuPAIqxEa3ty6/gZ6inKAtN3XpEHlY0l3JP3dW4/8WY=F.2d 370, 375 (10th vault:v1:zY+MoxdGVh0Vd6+ti6IL+lIOF6jYJ/rHktmKhu3CGg==) (en banc), cert. denied, vault:v1:yDFhMvjunQmhui8kI9zjCW8s90OrfczVqTMUy0VyBw==U.S. vault:v1:Ei6Czlz8G+/+cN0V/NQlxS0TC6jRfOO4tnfMXpJnyQ== vault:v1:+T54NBcMrotsv4TEVWknWbXrzx00t6Ocj4UOsQsuS.Ct. vault:v1:mlP3p7dluGBmv1HwmNHLu7HUBBXlBxDyDrBqmhy/ng== vault:v1:mJ+9JFR5YOrnPxmK6P2xp3keNiHFbbN5U1YhBRY8L.Ed.2d 338 (vault:v1:dFu0cAv0DqTj3SXIpY64+UdLo5WLBNOG9Mb1WEFnn6mM.\\n\\nThat line of cases was persuasive to Chief Judge vault:v1:UQjz/xt4RaP3SPjs6Q0DdUWSGe2WYTqpnX7/g3N8HS5xRA1WLZVKAlRHj/Teq4o=in dismissing a civil action challenging a notice of intention to seek the death penalty upon conviction of a charge of continuing criminal enterprise under vault:v1:3mpMRU9TexHPpQn67xahlhViHx6dBQFgPFtXTYtEGTsQmLRlz1NblQ5ywvCj0UkLhT3Y7nI=in vault:v1:jbXWqOcs/nC7kLBj2cwIkVIhqwBoB7zPCTndxtgPWv8ZU5zLZOKrf/nIQLl0EM/J0Uoyw57AVg==and vault:v1:NGbpC9RocQyCTolEVMHcIQKk3XzOMop30esI6LGtIKsiixK4Pe+fH2tTv. vault:v1:Jd+mJPeWRVjIjyUo3Cp77e3zphErNKndqlXWubDVl1c= vault:v1:0WaEzeMdgoEBE8ogneMm8ChMBAR2pq/jpv01g30+858ixhZGuzDM124 (N.D.N.Y.1995). Mr. vault:v1:D+I+5abaJ1EJT+z7gvEkItdB9EmTXRS65PkyyKKmUuzSBlk= counsel seeks to distinguish that holding from this case because the court there noted that there was no contention that the Attorney General had failed to follow the vault:v1:z2+5Di6N/2aDi/7qBa7A7hRtrojUc7lAVVZwD1qKP8qFcvHuwhereas the claim here is that she failed to follow even the minimum procedural protections in the vault:v1:UTB5ceoltssBYABqz0cS+8AxVuvehhE7u5Lj8iUeqa6+Bg==by her prejudgment of the death penalty issue in her public announcement made before any suspects had been named or arrested. Indeed, both Mr. vault:v1:01VMklZtEVBKlDxJpq83YuGiemHL+ev3zYdXVDT2PGsqcGpfhRFy/J8=and his co-defendant, vault:v1:q94dnjAfOKr7Q2HVflYH68SFGIzHAn+1xZ6AdKgjr08VfEVY9S4FbjQY0Q== have moved in the criminal case to strike the Notice and to disqualify the Attorney General from participating in the preparation of any new notice because of that public statement by General vault:v1:Jd+mJPeWRVjIjyUo3Cp77e3zphErNKndqlXWubDVl1c=and a publicly stated commitment to seek the death penalty made by the President of vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=at the beginning of the government\\u2019s investigation.\\n\\nThe suggested distinction between these cases depends upon the applicability of the principle that fundamental fairness requires a decision maker to address the question before her with an open mind free from any preconceptions concerning the outcome. That is, of course, a root requirement for any judicial proceeding and it is equally essential in any adjudicative or quasi-adjudicative action by officers of government. By definition a prosecutorial decision is not adjudicative in nature. It is a determination to seek a particular result in an adjudication conducted in a judicial forum with the full protection of the adversarial system of justice. The life of a defendant named in a notice of intention to seek the death penalty is protected by the trial process with the jurors making the final decision in the exercise of their authority as the conscience of the community.\\n\\nThe death penalty statute gives the prosecutorial discretion to the vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=Attorney. The only legislative guidance is that he shall consider whether the \\u201ccircumstances of the offense\\u201d justifies a sentence of death. There is no other direction. Thus, absent the vault:v1:z2+5Di6N/2aDi/7qBa7A7hRtrojUc7lAVVZwD1qKP8qFcvHu Mr. vault:v1:ODFyscgoEz8/RP9o5XTMePJqNTjYu16pH0UvkDqEJAo=had the statutory authority to file the notice as soon as he believed that there was sufficient evidence to show that the explosion on vault:v1:h3wAd8k8EPvOt9sam7q4ET0TUgwLP+eRWBsvA8vVnGBWLncPCZAKPG6uD3k=was caused by an intentional bombing.\\n\\nThere is some suggestion that because General vault:v1:Jd+mJPeWRVjIjyUo3Cp77e3zphErNKndqlXWubDVl1c=advised persons in vault:v1:S11PseeNuZ/aCdyzDAYndVvTimC+km9trPHveKiU1ND5XFHm2s+ABXk2KDhMAz5+Hx0=that she would exercise her supervisory authority over vault:v1:113xFnOHKT2HX3mGWhwPusHJGwX3xW1Cvt6vlMbC6VqyKrGBk0W3C90=Attorneys to avoid abusive or invidiously discriminatory prosecutions the Protocol is an implied provision of the statute. That argument is rejected. There is no ambiguity in the statutory language justifying reverting to such scant legislative history to determine the intent of vault:v1:S11PseeNuZ/aCdyzDAYndVvTimC+km9trPHveKiU1ND5XFHm2s+ABXk2KDhMAz5+Hx0=\\n\\nIt is also suggested that the constitutionality of the federal death penalty requires such a procedure. The arguments against the constitutional validity have been made by both defendants in their motions filed in the criminal case and will be decided in that context where the adequacy of the filed Notice is in question. This proceeding is a challenge to the process followed in the filing of the Notice and those questions of validity are not proeedurally appropriate here.\\n\\nThere has been no factual dispute that counsel for Mr. vault:v1:D+I+5abaJ1EJT+z7gvEkItdB9EmTXRS65PkyyKKmUuzSBlk=had the opportunity to make presentations to Mr. vault:v1:ODFyscgoEz8/RP9o5XTMePJqNTjYu16pH0UvkDqEJAo=and to the committee to present reasons for not seeking the death penalty in the criminal case. The procedures of the vault:v1:z2+5Di6N/2aDi/7qBa7A7hRtrojUc7lAVVZwD1qKP8qFcvHuwere *753 followed. As noted earlier, the charge of bias based solely on the public statements of the President and the Attorney General in the immediate aftermath of the explosion is legally insufficient to support a constitutional challenge to the Notice.\\n\\nvault:v1:YVv3KzKyNOkUFnn7AvIOo5nuA6LTucnaK4Y02P5NPyX8ZZFJMlp4ypTWzrRApD7jfwvoXD8ooznn9Q==requiring open meetings by agencies \\u201cheaded by a collegial body composed of vault:v1:E7LmpAqLgLfPgHSU9P+SdSSjBpJGq6g4x+enwReJfffeal1sUamJindividual members,\\u201d vault:v1:B6OfvBy1Zhw6dmFz4XvJnsScSdrdzbWr7d4CqznhF6yASCD91ascFarNyHVpM3uxw0k= is not applicable to vault:v1:uGgiAngIOh6lIHqNSRRD3BpehHxPzr2yXX5ZD4vJ2GtB+lduZYiMHmmL1nhVDg+qvZhYkIDsQYkCuyLc73eN As previously observed, the authority of vault:v1:uGgiAngIOh6lIHqNSRRD3BpehHxPzr2yXX5ZD4vJ2GtB+lduZYiMHmmL1nhVDg+qvZhYkIDsQYkCuyLc73eNis vested in the Attorney General.\\n\\nUpon the foregoing, it is\\n\\nORDERED that the defendants\\u2019 motions to dismiss are granted and this civil action is dismissed with prejudice.\",\n",
      "  \"offset_type\": \"p\",\n",
      "  \"name\": \"_ANNOTATED\",\n",
      "  \"id\": \"d64b87c269a8fd9fa3ab6e799798f5e4ed5fd8a0fdbcefb31cecb073b6771ce5\",\n",
      "  \"metadata\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/l_fskgld3vddb2mq0h787wd40000gn/T/ipykernel_57020/352670684.py:13: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  return es.search(index=INDEX_NAME, body=search_query)\n"
     ]
    }
   ],
   "source": [
    "# Quick document search and inspection\n",
    "def search_documents(query=\"*\", size=10, exclude_fields=None):\n",
    "    \"\"\"Search documents in the index with optional field exclusions.\"\"\"\n",
    "    if exclude_fields is None:\n",
    "        exclude_fields = [\"chunks\", \"annotations\"]\n",
    "    \n",
    "    search_query = {\n",
    "        \"query\": {\"query_string\": {\"query\": query}},\n",
    "        \"_source\": {\"excludes\": exclude_fields},\n",
    "        \"size\": size,\n",
    "    }\n",
    "    \n",
    "    return es.search(index=INDEX_NAME, body=search_query)\n",
    "\n",
    "\n",
    "def find_empty_annotation_documents():\n",
    "    \"\"\"Find documents with empty annotations field.\"\"\"\n",
    "    search_query = {\n",
    "        \"query\": {\"query_string\": {\"query\": \"*\"}},\n",
    "        \"_source\": {\"excludes\": [\"chunks\", \"annotation_sets\"]},\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=INDEX_NAME, body=search_query)\n",
    "    empty_annotation_ids = []\n",
    "    \n",
    "    for hit in response[\"hits\"][\"hits\"]:\n",
    "        if hit[\"_source\"].get(\"annotations\") == []:\n",
    "            name = hit[\"_source\"].get(\"name\", \"(no name)\")\n",
    "            print(f\"Document with empty 'annotations' field: {name}\")\n",
    "            empty_annotation_ids.append(hit[\"_source\"][\"id\"])\n",
    "    \n",
    "    return empty_annotation_ids\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sample_response = search_documents(size=1)\n",
    "if sample_response[\"hits\"][\"hits\"]:\n",
    "    print(\"Sample document:\")\n",
    "    print(json.dumps(sample_response[\"hits\"][\"hits\"][0][\"_source\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing index: anonymized\n",
      "Created index: anonymized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/l_fskgld3vddb2mq0h787wd40000gn/T/ipykernel_57020/1619132199.py:65: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es.indices.create(index=index_name, body=index_settings)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'anonymized'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_index_settings():\n",
    "    \"\"\"Get the index settings with custom nested object limit.\"\"\"\n",
    "    return {\n",
    "        \"settings\": {\n",
    "            \"index.mapping.nested_objects.limit\": 20000\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text\": {\"type\": \"text\"},\n",
    "                \"name\": {\"type\": \"keyword\"},\n",
    "                \"preview\": {\"type\": \"keyword\"},\n",
    "                \"id\": {\"type\": \"keyword\"},\n",
    "                \"metadata\": {\n",
    "                    \"type\": \"nested\",\n",
    "                    \"properties\": {\n",
    "                        \"type\": {\"type\": \"keyword\"},\n",
    "                        \"value\": {\"type\": \"keyword\"}\n",
    "                    }\n",
    "                },\n",
    "                \"annotations\": {\n",
    "                    \"type\": \"nested\",\n",
    "                    \"properties\": {\n",
    "                        \"mention\": {\"type\": \"keyword\"},\n",
    "                        \"start\": {\"type\": \"integer\"},\n",
    "                        \"end\": {\"type\": \"integer\"},\n",
    "                        \"display_name\": {\"type\": \"keyword\"},\n",
    "                        \"id\": {\"type\": \"integer\"},\n",
    "                        \"type\": {\"type\": \"keyword\"},\n",
    "                        \"is_linked\": {\"type\": \"boolean\"},\n",
    "                        \"id_ER\": {\"type\": \"keyword\"}\n",
    "                    }\n",
    "                },\n",
    "                \"chunks\": {\n",
    "                    \"type\": \"nested\",\n",
    "                    \"properties\": {\n",
    "                        \"vectors\": {\n",
    "                            \"type\": \"nested\",\n",
    "                            \"properties\": {\n",
    "                                \"predicted_value\": {\n",
    "                                    \"type\": \"dense_vector\",\n",
    "                                    \"index\": True,\n",
    "                                    \"dims\": VECTOR_DIMS,\n",
    "                                    \"similarity\": \"cosine\",\n",
    "                                },\n",
    "                                \"text\": {\"type\": \"text\"},\n",
    "                                \"entities\": {\"type\": \"text\"},\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def recreate_index(index_name=INDEX_NAME, delete_existing=False):\n",
    "    \"\"\"Create or recreate the Elasticsearch index.\"\"\"\n",
    "    try:\n",
    "        if delete_existing and es.indices.exists(index=index_name):\n",
    "            es.indices.delete(index=index_name)\n",
    "            print(f\"Deleted existing index: {index_name}\")\n",
    "        \n",
    "        if not es.indices.exists(index=index_name):\n",
    "            index_settings = get_index_settings()\n",
    "            response = es.indices.create(index=index_name, body=index_settings)\n",
    "            print(f\"Created index: {index_name}\")\n",
    "            return response\n",
    "        else:\n",
    "            print(f\"Index {index_name} already exists\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error managing index: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Uncomment the line below to recreate the index\n",
    "recreate_index(delete_existing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_files(path, target_ids=None):\n",
    "    \"\"\"\n",
    "    Read and process JSON annotation files from a directory.\n",
    "    \n",
    "    Args:\n",
    "        path: Directory containing .json.annotated files\n",
    "        target_ids: Optional set of document IDs to filter by\n",
    "        \n",
    "    Returns:\n",
    "        List of processed document objects\n",
    "    \"\"\"\n",
    "    json_files = [f for f in os.listdir(path) if f.endswith(\".json\")]\n",
    "    data = []\n",
    "    \n",
    "    print(f\"Processing {len(json_files)} JSON files from {path}\")\n",
    "    \n",
    "    for json_file in tqdm(json_files, desc=\"Reading files\"):\n",
    "        try:\n",
    "            with open(os.path.join(path, json_file), \"r\") as file:\n",
    "                file_object = json.load(file)\n",
    "                \n",
    "                # Skip empty files\n",
    "                if not file_object.get(\"text\"):\n",
    "                    print(f\"Warning: Skipping empty file: {json_file}\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate document ID\n",
    "                file_object[\"id\"] = get_string_hash(file_object[\"text\"])\n",
    "                \n",
    "                # Filter by target IDs if provided\n",
    "                if target_ids and file_object[\"id\"] not in target_ids:\n",
    "                    continue\n",
    "                \n",
    "                # Process annotations\n",
    "                annotations = process_document_annotations(file_object)\n",
    "                file_object[\"annotations\"] = annotations\n",
    "                \n",
    "                # Clean up the document\n",
    "                file_object = clean_document_data(file_object)\n",
    "                \n",
    "                data.append(file_object)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Successfully processed {len(data)} documents\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def process_document_annotations(file_object):\n",
    "    \"\"\"Extract and process annotations from a document.\"\"\"\n",
    "    text = file_object.get(\"text\", \"\")\n",
    "    annotations = []\n",
    "    \n",
    "    annotation_sets = file_object.get(\"annotation_sets\", {})\n",
    "    entities = annotation_sets.get(\"entities_\", {})\n",
    "    raw_annotations = entities.get(\"annotations\", [])\n",
    "    \n",
    "    for annotation in raw_annotations:\n",
    "        try:\n",
    "            ann_object = process_annotation(annotation, text, file_object.get(\"id\", \"\"))\n",
    "            annotations.append(ann_object)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error processing annotation: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Processed {len(annotations)} annotations for document '{file_object.get('name', 'Unknown')}'\")\n",
    "    return annotations\n",
    "\n",
    "\n",
    "def send_to_elasticsearch(data, index_name=INDEX_NAME, update_existing=True):\n",
    "    \"\"\"\n",
    "    Send documents to Elasticsearch with optional duplicate handling.\n",
    "    \n",
    "    Args:\n",
    "        data: List of document objects\n",
    "        index_name: Target index name\n",
    "        update_existing: Whether to update existing documents\n",
    "    \"\"\"\n",
    "    print(f\"Sending {len(data)} documents to Elasticsearch...\")\n",
    "    \n",
    "    for item in tqdm(data, desc=\"Indexing documents\"):\n",
    "        try:\n",
    "            if update_existing:\n",
    "                # Remove existing documents with same ID\n",
    "                search_query = {\"query\": {\"term\": {\"id\": item[\"id\"]}}}\n",
    "                search_response = es.search(index=index_name, body=search_query)\n",
    "                \n",
    "                for hit in search_response[\"hits\"][\"hits\"]:\n",
    "                    es.delete(index=index_name, id=hit[\"_id\"])\n",
    "            \n",
    "            # Index the new document\n",
    "            es.index(index=index_name, body=item)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error indexing document {item.get('name', 'Unknown')}: {e}\")\n",
    "    \n",
    "    print(\"Document indexing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 JSON files from ./out_anon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|██████████| 1/1 [00:00<00:00, 29.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 257 annotations for document '_ANNOTATED'\n",
      "Successfully processed 1 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process documents - you can filter by specific document IDs if needed\n",
    "# empty_annotation_ids = find_empty_annotation_documents()  # Uncomment to filter\n",
    "target_ids = None  # or set to empty_annotation_ids to process only those documents\n",
    "\n",
    "data = read_json_files(JSON_FOLDER, target_ids=target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents ready for processing\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(data)} documents ready for processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending 1 documents to Elasticsearch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing documents:   0%|          | 0/1 [00:00<?, ?it/s]/var/folders/d4/l_fskgld3vddb2mq0h787wd40000gn/T/ipykernel_57020/2021533814.py:88: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  search_response = es.search(index=index_name, body=search_query)\n",
      "/var/folders/d4/l_fskgld3vddb2mq0h787wd40000gn/T/ipykernel_57020/2021533814.py:94: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use the 'document' parameter. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  es.index(index=index_name, body=item)\n",
      "Indexing documents: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document indexing completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "send_to_elasticsearch(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Chunking and Vector Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping for chunk vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This mapping update is now included in the main index creation\n",
    "# No need to run separately if using recreate_index() function\n",
    "print(\"Vector mapping is included in the main index configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: Alibaba-NLP/gte-multilingual-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "class DocumentChunker:\n",
    "    \"\"\"Handles document chunking and embedding generation.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=MODEL_NAME, device=\"mps\"):\n",
    "        \"\"\"Initialize the chunker with sentence transformer model.\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self._model = None\n",
    "        self._initialize_model()\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        \"\"\"Lazy initialization of the sentence transformer model.\"\"\"\n",
    "        if self._model is None:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self._model = SentenceTransformer(\n",
    "                self.model_name, \n",
    "                trust_remote_code=True\n",
    "            ).to(self.device)\n",
    "            print(\"Model loaded successfully\")\n",
    "    \n",
    "    def generate_chunks_with_embeddings(self, text):\n",
    "        \"\"\"\n",
    "        Split text into chunks and generate embeddings for each chunk.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text to chunk and embed\n",
    "            \n",
    "        Returns:\n",
    "            List of lists: [embedding, chunk_text, entities_placeholder]\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Split text into chunks\n",
    "            chunks = text_splitter.split_text(text)\n",
    "            \n",
    "            if not chunks:\n",
    "                print(\"Warning: No chunks generated from text\")\n",
    "                return []\n",
    "            \n",
    "            # Generate embeddings\n",
    "            embeddings = self._model.encode(chunks, show_progress_bar=False)\n",
    "            \n",
    "            # Return as list of lists (mutable) instead of tuples (immutable)\n",
    "            result = [[emb.tolist(), chunk, \"\"] for emb, chunk in zip(embeddings, chunks)]\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in chunking/embedding: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_entities_from_chunk(self, chunk_text, full_text, annotations):\n",
    "        \"\"\"\n",
    "        Find entities from annotations that are present in the chunk text.\n",
    "        \n",
    "        Args:\n",
    "            chunk_text: The text of the current chunk\n",
    "            full_text: The full document text \n",
    "            annotations: List of annotation objects\n",
    "        \n",
    "        Returns:\n",
    "            String of entity mentions found in the chunk\n",
    "        \"\"\"\n",
    "        chunk_entities = []\n",
    "        \n",
    "        # Find the position of this chunk in the full text\n",
    "        chunk_start_in_full = full_text.find(chunk_text)\n",
    "        if chunk_start_in_full == -1:\n",
    "            return \"\"\n",
    "        \n",
    "        chunk_end_in_full = chunk_start_in_full + len(chunk_text)\n",
    "        \n",
    "        # Check which annotations overlap with this chunk\n",
    "        for annotation in annotations:\n",
    "            ann_start = annotation.get(\"start\", 0)\n",
    "            ann_end = annotation.get(\"end\", 0)\n",
    "            \n",
    "            # Check if annotation overlaps with chunk boundaries\n",
    "            if ((ann_start >= chunk_start_in_full and ann_start < chunk_end_in_full) or \n",
    "                (ann_end > chunk_start_in_full and ann_end <= chunk_end_in_full) or \n",
    "                (ann_start <= chunk_start_in_full and ann_end >= chunk_end_in_full)):\n",
    "                \n",
    "                entity_mention = full_text[ann_start:ann_end]\n",
    "                chunk_entities.append(entity_mention)\n",
    "        \n",
    "        return \" \".join(chunk_entities)\n",
    "\n",
    "\n",
    "# Initialize the chunker\n",
    "chunker = DocumentChunker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for documents to process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/l_fskgld3vddb2mq0h787wd40000gn/T/ipykernel_57020/3966881953.py:65: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es.search(index=index_name, body=search_body, size=batch_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 documents to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding chunks and embeddings:   0%|          | 0/1 [00:00<?, ?it/s]/var/folders/d4/l_fskgld3vddb2mq0h787wd40000gn/T/ipykernel_57020/3966881953.py:43: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es.update(index=INDEX_NAME, id=doc_id, body=data)\n",
      "Adding chunks and embeddings: 100%|██████████| 1/1 [01:10<00:00, 70.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated document bzn87JkB6MMnAM0IKDcM with 81 chunks\n",
      "Document processing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def update_document_with_chunks(doc_id, doc_source, chunker_instance):\n",
    "    \"\"\"\n",
    "    Update a document with chunks and their entities using existing annotations.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: Elasticsearch document ID\n",
    "        doc_source: Full document source containing text and annotations\n",
    "        chunker_instance: DocumentChunker instance\n",
    "    \"\"\"\n",
    "    text = doc_source.get(\"text\", \"\")\n",
    "    existing_annotations = doc_source.get(\"annotations\", [])\n",
    "    \n",
    "    # Generate chunks with embeddings\n",
    "    chunks = chunker_instance.generate_chunks_with_embeddings(text)\n",
    "    \n",
    "    if not chunks:\n",
    "        print(f\"Warning: No chunks generated for document {doc_id}\")\n",
    "        return\n",
    "    \n",
    "    # Add entity information to each chunk\n",
    "    for chunk in chunks:\n",
    "        chunk_text = chunk[1]\n",
    "        chunk_entities = chunker_instance.get_entities_from_chunk(\n",
    "            chunk_text, text, existing_annotations\n",
    "        )\n",
    "        chunk[2] = chunk_entities  # Update entities placeholder\n",
    "    \n",
    "    # Prepare data for Elasticsearch update\n",
    "    passages_body = [\n",
    "        {\n",
    "            \"vectors\": {\n",
    "                \"predicted_value\": chunk[0],\n",
    "                \"entities\": chunk[2], \n",
    "                \"text\": chunk[1]\n",
    "            }\n",
    "        } \n",
    "        for chunk in chunks\n",
    "    ]\n",
    "    \n",
    "    # Update document in Elasticsearch\n",
    "    try:\n",
    "        data = {\"doc\": {\"chunks\": passages_body}}\n",
    "        response = es.update(index=INDEX_NAME, id=doc_id, body=data)\n",
    "        print(f\"Updated document {doc_id} with {len(chunks)} chunks\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating document {doc_id}: {e}\")\n",
    "\n",
    "\n",
    "def process_documents_for_chunking(index_name=INDEX_NAME, query=None, batch_size=10000):\n",
    "    \"\"\"\n",
    "    Process documents from Elasticsearch to add chunks and embeddings.\n",
    "    \n",
    "    Args:\n",
    "        index_name: Index to search\n",
    "        query: Optional query to filter documents\n",
    "        batch_size: Maximum documents to process\n",
    "    \"\"\"\n",
    "    if query is None:\n",
    "        query = {\"match_all\": {}}\n",
    "    \n",
    "    search_body = {\"query\": query}\n",
    "    \n",
    "    try:\n",
    "        print(\"Searching for documents to process...\")\n",
    "        response = es.search(index=index_name, body=search_body, size=batch_size)\n",
    "        documents = response[\"hits\"][\"hits\"]\n",
    "        \n",
    "        print(f\"Found {len(documents)} documents to process\")\n",
    "        \n",
    "        # Suppress Elasticsearch transport logging for cleaner output\n",
    "        logging.getLogger(\"elastic_transport\").setLevel(logging.WARNING)\n",
    "        \n",
    "        # Process documents in reverse order (optional)\n",
    "        documents.reverse()\n",
    "        \n",
    "        # Process each document\n",
    "        for doc in tqdm(documents, desc=\"Adding chunks and embeddings\"):\n",
    "            doc_id = doc[\"_id\"]\n",
    "            doc_source = doc[\"_source\"]\n",
    "            update_document_with_chunks(doc_id, doc_source, chunker)\n",
    "            \n",
    "        print(\"Document processing completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during document processing: {e}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "process_documents_for_chunking()  # Process all documents\n",
    "# process_documents_for_chunking(query={\"terms\": {\"id\": specific_ids}})  # Process specific documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-video-upscaler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
